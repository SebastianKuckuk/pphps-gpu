{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c45741e6",
   "metadata": {},
   "source": [
    "# Target Offloading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d93f99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29656a37",
   "metadata": {},
   "source": [
    "The material of this course is provided mainly in the form of Jupyter Notebooks.\n",
    "In case you are not familiar with them:\n",
    "* Notebooks are comprised of **cells**.\n",
    "* Important cell types are\n",
    "    * **Text cells** which are written using [Markdown](https://www.markdownguide.org/) - double click this text to see it.\n",
    "    * **Code cells** which contain Python code to be executed.\n",
    "* Cells can be executed with\n",
    "    * the play button above,\n",
    "    * via the menu,\n",
    "    * by typing *ctrl + return* to execute and stay with the current cell, or\n",
    "    * with *shift + return* to execute and move to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ccb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello world from a Python cell')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1696fe2",
   "metadata": {},
   "source": [
    "Apart from executing Python code, which is not really useful for *this* tutorial, code cells can also execute terminal commands by prefixing them with `!`.\n",
    "The below cell calls `nvidia-smi`, the *Nvidia System Management Interface*, that reports real-time information about installed Nvidia GPU devices including\n",
    "* utilization,\n",
    "* memory usage,\n",
    "* temperature, and\n",
    "* running processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e4937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d0f31c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ICE Magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08faa9",
   "metadata": {},
   "source": [
    "The last way to use code cells that is relevant for this tutorial are **magic commands**.\n",
    "The below cell loads an extension called **ICE**, short for instantiate-compile-execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b45d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ice.magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c555c2d",
   "metadata": {},
   "source": [
    "After the extension is loaded, we can use the `%%cpp` magic command.\n",
    "It takes the remaining contents of the cell it is included in and does the following steps:\n",
    "* *Instantiate*: The code provided is augmented with auxiliary boilerplate code such as standard includes and written to file.\n",
    "* *Compile*: The generated file is compiled to a binary.\n",
    "* *Execute*: The binary is executed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899af96e",
   "metadata": {},
   "source": [
    "We start with a simple hello world example to illustrate how ICE can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb3713",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp\n",
    "  ðŸ‘†\n",
    "\n",
    "printf(\"Hello world from a compiled application\\n\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37321d6",
   "metadata": {},
   "source": [
    "Our magic function also takes additional parameters which can be displayed with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9951c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp --help\n",
    "//#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3940f5c",
   "metadata": {},
   "source": [
    "Let's specify the (code) output file as well as add the *verbose* and *display* flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d3c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp -o code/hello-world.cpp -v -d\n",
    "                              ðŸ‘† ðŸ‘†\n",
    "\n",
    "printf(\"Hello world from a compiled application\\n\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38186503",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## GPU Programming Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edf05f9",
   "metadata": {},
   "source": [
    "We start by reviewing a short presentation.\n",
    "Execute the cell below to display it or download and open it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c0ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<div align=\"center\"><iframe src=\"slides/PPHPS-GPU.pdf\" width=800 height=500 frameborder=0></iframe></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ed45c",
   "metadata": {},
   "source": [
    "\n",
    "In contrast to other GPU programming approaches, OpenMP follows a slightly different naming convention ([OpenMP 5.1 - 1.2.1](https://www.openmp.org/spec-html/5.1/openmpsu1.html)).\n",
    "* A *device* is 'an implementation-defined logical execution engine'.\n",
    "* The *host*, or *initial device*, is the device on which the OpenMP program begins execution.\n",
    "* The *target* is a device onto which code and data may be offloaded from the host device. In many cases it is a GPU, but it doesn't have to be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29019c8d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## OpenMP Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd9acc8",
   "metadata": {},
   "source": [
    "Before we dive deeper, make sure to load the ICE magic commands with the below cell.\n",
    "This allows executing all following code examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a06951",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ice.magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b5964",
   "metadata": {},
   "source": [
    "The `target` construct transfers execution to the device (target) ([OpenMP 5.1 - 2.14.5](https://www.openmp.org/spec-html/5.1/openmpsu68.html)).\n",
    "\\\n",
    "Everything within the target block is executed on the target.\n",
    "Only a sub-set of features is available, e.g. no `std::cout`. If you are familiar with other GPU programming approaches -- similar restrictions apply with OpenMP as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c620e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/hello-target.cpp\n",
    "\n",
    "std::cout << \"Hello from the CPU\" << std::endl;\n",
    "\n",
    "#pragma omp target\n",
    "{           ðŸ‘†\n",
    "    printf(\"Hello from the GPU\\n\");\n",
    "} //# implicit synchronization with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a725b2",
   "metadata": {},
   "source": [
    "### Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a73a1",
   "metadata": {},
   "source": [
    "You might have noticed that we used a different magic than discussed in the introduction -- `cpp_omp_target`.\n",
    "\\\n",
    "This switches to a different compiler, `nvc++`, and adds a different set of flags.\n",
    "As before, using the `-v` switch displays more detailed information.\n",
    "\\\n",
    "Adding the optional `-Minfo=mp` compiler flag triggers the compiler to emit information about how the application is mapped to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc639eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/hello-target.cpp -v -f Minfo=mp\n",
    "\n",
    "std::cout << \"Hello from the CPU\" << std::endl;\n",
    "\n",
    "#pragma omp target\n",
    "{\n",
    "    printf(\"Hello from the GPU\\n\");\n",
    "} //# implicit synchronization with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b14bad0",
   "metadata": {},
   "source": [
    "### Checking for Host Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9643c519",
   "metadata": {},
   "source": [
    "In some cases it might be necessary to programmatically check whether execution is currently on the host or on the device, e.g. when using multiple nested functions.\n",
    "`omp_is_initial_device` can be used to perform that check ([OpenMP 5.1 - 3.7.6](https://www.openmp.org/spec-html/5.1/openmpsu166.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430edb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/initial-device.cpp\n",
    "\n",
    "std::cout << omp_is_initial_device() << std::endl;\n",
    "             ðŸ‘†\n",
    "\n",
    "#pragma omp target\n",
    "{\n",
    "    printf(\"%d\\n\", omp_is_initial_device());\n",
    "                   ðŸ‘†\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb9521c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Parallel Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6facce12",
   "metadata": {},
   "source": [
    "So far, everything in our `target` region has been executed serially since the target construct doesn't generate parallelism.\n",
    "\\\n",
    "In the following steps, we will add hierarchical parallelism (to match the GPU architecture discussed before), and workload sharing.\n",
    "\\\n",
    "We will use the the following example as baseline.\n",
    "In it, the loop is executed on the device, but only with a single thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a75583",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target-serial.cpp\n",
    "\n",
    "#pragma omp target\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    printf(\"%d\\n\", i);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86ba0e8",
   "metadata": {},
   "source": [
    "### Teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65078545",
   "metadata": {},
   "source": [
    "`teams` construct generates a *league of teams* ([OpenMP 5.1 - 2.7](https://www.openmp.org/spec-html/5.1/openmpse15.html)).\n",
    "\\\n",
    "A team is comparable but not necessarily identical to a CUDA thread block.\n",
    "Each team initially has only one thread and each team executes the same code.\n",
    "The number of teams can be *limited* with `num_teams` -- this sets an upper bound, not the exact number.\n",
    "\n",
    "The id of the current team can be querried with `omp_get_team_num` ([OpenMP 5.1 - 3.4.2](https://www.openmp.org/spec-html/5.1/openmpsu152.html)).\n",
    "\\\n",
    "`omp_get_thread_num` returns the current thread id *within the current team*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cccba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target-teams.cpp\n",
    "\n",
    "#pragma omp target\n",
    "#pragma omp teams num_teams(2)\n",
    "            ðŸ‘†   ðŸ‘†\n",
    "    printf(\"Team %d, thread %d\\n\", omp_get_team_num(), omp_get_thread_num());\n",
    "                                   ðŸ‘†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83947857",
   "metadata": {},
   "source": [
    "### Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cae64df",
   "metadata": {},
   "source": [
    "`parallel` generates a parallel region with multiple threads per team.\n",
    "The number of threads per team can be limited with `thread_limit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b1a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/thread-limit.cpp\n",
    "\n",
    "#pragma omp target\n",
    "#pragma omp teams parallel num_teams(2) thread_limit(2)\n",
    "                  ðŸ‘†                    ðŸ‘†\n",
    "    printf(\"Team %d, thread %d\\n\", omp_get_team_num(), omp_get_thread_num());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe27c9e",
   "metadata": {},
   "source": [
    "### Distribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f2e7d0",
   "metadata": {},
   "source": [
    "For loops, worksharing constructs are required additionally.\n",
    "\n",
    "`distribute` distributes the iteration space across teams ([OpenMP 5.1 - 2.11.6](https://www.openmp.org/spec-html/5.1/openmpsu50.html)).\n",
    "\\\n",
    "Schedules can be specified using `dist_schedule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5bc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target-distribute.cpp\n",
    "\n",
    "#pragma omp target\n",
    "#pragma omp teams num_teams(2)\n",
    "#pragma omp distribute\n",
    "            ðŸ‘†\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    printf(\"Team %d, thread %d, i = %d\\n\", omp_get_team_num(), omp_get_thread_num(), i);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc962f2",
   "metadata": {},
   "source": [
    "### For"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7f34f7",
   "metadata": {},
   "source": [
    "`for` distributes the *team's* iteration space over the team's threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target-for.cpp\n",
    "\n",
    "#pragma omp target\n",
    "#pragma omp teams num_teams(2)\n",
    "#pragma omp distribute parallel for\n",
    "                                ðŸ‘†\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    printf(\"Team %d, thread %d, i = %d\\n\", omp_get_team_num(), omp_get_thread_num(), i);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee7f495",
   "metadata": {},
   "source": [
    "### SIMD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9757a",
   "metadata": {},
   "source": [
    "Additionally, the `simd` construct is also available.\n",
    "What exactly is mapped how is compiler dependent.\n",
    "For NVIDIA, *usually* teams are mapped to CUDA thread blocks, threads are mapped to CUDA threads and simd is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03682159",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target-simd.cpp\n",
    "\n",
    "#pragma omp target teams distribute parallel for simd\n",
    "                                                 ðŸ‘†\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    printf(\"Team %d, thread %d, i = %d\\n\", omp_get_team_num(), omp_get_thread_num(), i);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6550175-df0a-424f-9e20-6160f8f0da46",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ed7d14-2b48-4bee-8761-3a42ee4531bf",
   "metadata": {},
   "source": [
    "Since OpenMP 5, the alternative `target teams loop` construct is available, which serves as a shorthand.\n",
    "Since OpenMP 6, there is also `target loop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab200a2-2c24-4265-8f61-bcb503d72982",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target-loop.cpp\n",
    "\n",
    "#pragma omp target teams loop\n",
    "                    ðŸ‘†   ðŸ‘†\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    printf(\"Team %d, thread %d, i = %d\\n\", omp_get_team_num(), omp_get_thread_num(), i);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09500d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## An Aside on Managed Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067e510-dcbb-4589-a952-c96c028b401f",
   "metadata": {},
   "source": [
    "On newer architecture, managed memory or unified memory is available (see, e.g., this [blog post](https://developer.nvidia.com/blog/unified-memory-cuda-beginners/)).\n",
    "When used, allocations are done as managed memory and all transfers between host and target are done implicitly.\n",
    "We will start with this version since it requires less coding effort and is more robust for most use cases when beginning with GPU programming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df9bc8b",
   "metadata": {},
   "source": [
    "~~In OpenMP it is activated by adding the compiler flag `-gpu=managed` and by specifying `#pragma omp requires unified_shared_memory`.~~\n",
    "\\\n",
    "In newer versions of the NVC++ compiler, the flag is now `-gpu=mem:managed`.\n",
    "Additionally, `#pragma omp requires unified_shared_memory` now requires `-gpu=mem:unified` and is only available on systems that support full CUDA Unified Memory capability (e.g. Nvidia Grace Hopper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/managed-mem.cpp -v -f gpu=mem:managed\n",
    "                                                   ðŸ‘†\n",
    "\n",
    "//# #pragma omp requires unified_shared_memory\n",
    "ðŸ‘†\n",
    "\n",
    "int *vec = new int[10];\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] = i;\n",
    "\n",
    "#pragma omp target teams distribute parallel for // no map clauses\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] *= 2;\n",
    "\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    std::cout << vec[i] << \" \";\n",
    "std::cout << std::endl;\n",
    "\n",
    "free(vec);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a65285",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise: Stream Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611131b",
   "metadata": {},
   "source": [
    "The stream benchmark application can be used to assess bandwidth.\n",
    "\\\n",
    "It copies data between two arrays in a ping-pong fashion, each time increasing each element by one.\n",
    "The latter allows for checking correctness of the implemented operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da396a7b",
   "metadata": {},
   "source": [
    "The serial baseline code is available at [code/exercise/stream.cpp](code/exercise/stream.cpp).\n",
    "It can be compiled and executed using the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df526328",
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -O3 -march=native -std=c++17 -Wall -o code/exercise/stream code/exercise/stream.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677640a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!code/exercise/stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cf9e51",
   "metadata": {},
   "source": [
    "Optionally, the default parameters can be overwritten with `./stream num_elements num_repetitions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf75791",
   "metadata": {},
   "outputs": [],
   "source": [
    "!code/exercise/stream $((1024 * 1024)) 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bbdc46",
   "metadata": {},
   "source": [
    "Your task is to refactor the application to use OpenMP target offloading to accelerate the main kernel.\n",
    "Use managed memory for this version.\n",
    "\\\n",
    "You can compile and execute the application with the cells below after addressing the remaining TODOs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e497a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!(TODO:compiler) (TODO:general-flags) (TODO:omp-flags) (TODO:managed-mem) -o code/exercise/stream code/exercise/stream.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "!code/exercise/stream $((64 * 1024 * 1024)) 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c1c84-db89-42d4-acc6-788cb8e1b0b1",
   "metadata": {},
   "source": [
    "After you have implemented a correct version (`Stream check completed` is printed at the end), evaluate performance for different configurations:\n",
    "\n",
    "* Is the estimated bandwidth constant for all iterations?\n",
    "* Does the bandwidth depend on the problem size (number of elements)?\n",
    "* Does specifying/ changing `num_teams` and `thread_limit` affect the performance?\n",
    "\n",
    "Remember that you can get additional information about parallelization applied by the compiler with `-Minfo=mp`.\n",
    "Additionally setting the environment variable `NVCOMPILER_ACC_NOTIFY=1` when executing will print execution configuration information for every kernel executed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6866285-1cd7-4e2e-84d4-1214c4d2bc39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Possible Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb7020-df99-4da4-b7bf-75fc0761f33d",
   "metadata": {},
   "source": [
    "A possible solution is given in [code/solution/stream.cpp](code/solution/stream.cpp).\n",
    "It can be compiled and executed using the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa3496b-1581-4236-8ea4-163d085df0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvc++ -O3 -std=c++17 -mp=gpu -gpu=mem:managed -Minfo=mp -o code/solution/stream code/solution/stream.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e67ad2-9c0d-4d45-a200-341bb0026344",
   "metadata": {},
   "outputs": [],
   "source": [
    "!NVCOMPILER_ACC_NOTIFY=1 code/solution/stream $((64 * 1024 * 1024)) 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41db3a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Target Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a06f7d3",
   "metadata": {},
   "source": [
    "Managed memory is a powerful tool, but can have negative effects on performance, as seen in the previous exercise.\n",
    "The main alternative is taking control over memory placement, allocation and movement.\n",
    "OpenMP supports this through `target data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0873a7d9",
   "metadata": {},
   "source": [
    "Each target region spans its own data environment.\n",
    "In addition to the clauses already discussed in the OpenMP for CPU part, target data mapping clauses are available.\n",
    "Let's consider the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510896e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target-map.cpp\n",
    "\n",
    "int *vec = new int[10];\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] = i;\n",
    "\n",
    "#pragma omp target teams distribute parallel for map(tofrom: vec[0:10])\n",
    "                                                 ðŸ‘†\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] *= 2;\n",
    "\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    std::cout << vec[i] << \" \";\n",
    "std::cout << std::endl;\n",
    "\n",
    "free(vec);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c645b7",
   "metadata": {},
   "source": [
    "Here, the contents of `vec` are copied to the target when entering the target region and copied back to the host when leaving it.\n",
    "Available map types in the `map` clause are\n",
    "* `to` which copies data from host to target,\n",
    "* `from` which copies data from target to host,\n",
    "* `tofrom` which combines the behavior of to and from, and\n",
    "* `alloc` which allocates data on the target but does not initialize it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a195f170",
   "metadata": {},
   "source": [
    "### Implicit Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284890a3",
   "metadata": {},
   "source": [
    "Target data environments implement the following implicit behavior if not specified otherwise:\n",
    "* Scalar variables are `firstprivate`\n",
    "    * They are copied to the device and each thread has its own version\n",
    "    * Changes are neither synchronized between threads nor copied back to the host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e61290",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/implicit-data.cpp\n",
    "\n",
    "int a = 10;\n",
    "   ðŸ‘†\n",
    "static int b = 20;\n",
    "          ðŸ‘†\n",
    "\n",
    "#pragma omp target teams parallel\n",
    "if (0 == omp_get_team_num() && 0 == omp_get_thread_num()) {\n",
    "    printf(\"a = %d, b = %d\\n\", a, b);\n",
    "    a *= 10;\n",
    "    b *= 10;\n",
    "}\n",
    "\n",
    "printf(\"a = %d, b = %d\\n\", a, b);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe9ced",
   "metadata": {},
   "source": [
    "* Statically allocated arrays are treated as `map(tofrom)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8995cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/static-array.cpp\n",
    "\n",
    "int vec[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n",
    "    ðŸ‘†\n",
    "\n",
    "#pragma omp target teams distribute parallel for\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] *= 2;\n",
    "\n",
    "for (const auto& val : vec)\n",
    "    std::cout << val << \" \";\n",
    "std::cout << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf6db13",
   "metadata": {},
   "source": [
    "* Dynamically allocated arrays need to be mapped explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4b53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/missing-map.cpp\n",
    "\n",
    "int *vec = new int[10];\n",
    "    ðŸ‘†\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] = i;\n",
    "\n",
    "#pragma omp target teams distribute parallel for\n",
    "//# due to the missing map clause, this example will not work\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] *= 2;\n",
    "\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    std::cout << vec[i] << \" \";\n",
    "std::cout << std::endl;\n",
    "\n",
    "free(vec);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35610f00",
   "metadata": {},
   "source": [
    "### Target Data Region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521b4703",
   "metadata": {},
   "source": [
    "Mapping data for each target region individually can generate some drawbacks (code bloating, performance issues).\n",
    "OpenMP offers `target data` constructs as an alternative ([OpenMP 5.1 - 2.14.2](https://www.openmp.org/spec-html/5.1/openmpsu65.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7fb1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target-data.cpp\n",
    "\n",
    "int *vec = new int[10];\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] = i;\n",
    "\n",
    "#pragma omp target data map(tofrom: vec[0:10])\n",
    "{                 ðŸ‘†\n",
    "    #pragma omp target teams distribute parallel for\n",
    "    for (auto i = 0; i < 10; ++i)\n",
    "        vec[i] *= 2;\n",
    "\n",
    "    #pragma omp target teams distribute parallel for\n",
    "    for (auto i = 0; i < 10; ++i)\n",
    "        vec[i] *= 2;\n",
    "}\n",
    "\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    std::cout << vec[i] << \" \";\n",
    "std::cout << std::endl;\n",
    "\n",
    "free(vec);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a8dcb7",
   "metadata": {},
   "source": [
    "If the software architecture requires a more unstructured approach `target enter data` ([OpenMP 5.1 - 2.14.3](https://www.openmp.org/spec-html/5.1/openmpsu66.html)) and `target exit data` ([OpenMP 5.1 - 2.14.4](https://www.openmp.org/spec-html/5.1/openmpsu67.html)) are available.\n",
    "These can be helpful when performing the mapping in separate functions, e.g. in the constructor and destructor of a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b7b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target-enter-data.cpp\n",
    "\n",
    "int *vec = new int[10];\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] = i;\n",
    "\n",
    "#pragma omp target enter data map(to: vec[0:10])\n",
    "                  ðŸ‘†\n",
    "\n",
    "#pragma omp target teams distribute parallel for\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] *= 2;\n",
    "\n",
    "#pragma omp target exit data map(from: vec[0:10])\n",
    "                  ðŸ‘†\n",
    "\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    std::cout << vec[i] << \" \";\n",
    "std::cout << std::endl;\n",
    "\n",
    "free(vec);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd27686",
   "metadata": {},
   "source": [
    "For `target enter data`, the map clause must be either `to` or `alloc`.\n",
    "For `target exit data`, the map clause must be either `from`, `release`, or `delete`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb89ea4-f783-4aa9-b7e5-1943f3d18002",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise: Revise Stream Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a610a",
   "metadata": {},
   "source": [
    "Your task is to refactor the stream benchmark to use explicit target data regions (or unstructured equivalents).\n",
    "The code, which you probably altered in the last exercise, is still available at [code/exercise/stream.cpp](code/exercise/stream.cpp).\n",
    "In case you missed the last exercise, feel free to copy the contents of [code/solution/stream.cpp](code/solution/stream.cpp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0737ac46",
   "metadata": {},
   "source": [
    "Start the refactoring by adding data mappings to the main loop **only**.\n",
    "\n",
    "```c++\n",
    "#pragma omp target ...\n",
    "for (size_t i = 0; i < nx; ++i)\n",
    "    dest[i] = src[i] + 1;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f5e39",
   "metadata": {},
   "source": [
    "You can compile and execute the application with the cells below afterwards (note the omitted `-gpu=mem:managed`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758cdef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvc++ -O3 -std=c++17 -mp=gpu -Minfo=mp -o code/exercise/stream code/exercise/stream.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7be5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!code/exercise/stream $((64 * 1024 * 1024)) 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa3d276",
   "metadata": {},
   "source": [
    "After you have implemented a correct version (`Stream check completed` is printed at the end), evaluate performance and compare it with the original version built on managed memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0835b3d0",
   "metadata": {},
   "source": [
    "Next, add another target data region around the main iteration loop\n",
    "\n",
    "```c++\n",
    "for (size_t i = 0; i < nIt; ++i) {\n",
    "    ...\n",
    "}\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvc++ -O3 -std=c++17 -mp=gpu -Minfo=mp -o code/exercise/stream code/solution/stream.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!code/exercise/stream $((64 * 1024 * 1024)) 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9125f6c8",
   "metadata": {},
   "source": [
    "After you have implemented a correct version (`Stream check completed` is printed at the end), evaluate performance once again and compare it with the two previous versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9bdb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Possible Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61986eee",
   "metadata": {},
   "source": [
    "A possible solution is given in [code/solution/stream-target-data.cpp](code/solution/stream-target-data.cpp).\n",
    "It can be compiled and executed using the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvc++ -O3 -std=c++17 -mp=gpu -Minfo=mp -o code/solution/stream code/solution/stream-target-data.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca59d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!NVCOMPILER_ACC_NOTIFY=1 code/solution/stream $((64 * 1024 * 1024)) 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf526ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Collapsing Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1664c77",
   "metadata": {},
   "source": [
    "Similar to how loops are handled on CPU, `collapse` can be used to merge multiple loops in a perfect nest.\n",
    "This is especially important on GPUs since massive parallelism is required to fully utilize the hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c468dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/collapse.cpp\n",
    "\n",
    "#pragma omp target teams distribute parallel for simd collapse(2)\n",
    "                                                      ðŸ‘†\n",
    "for (auto i = 0; i < 2; ++i)\n",
    "    for (auto j = 0; j < 5; ++j)\n",
    "        printf(\"Team %d, thread %d, i = %d\\n\", omp_get_team_num(), omp_get_thread_num(), i * 5 + j);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6d35a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reductions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f4a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/reduction.cpp\n",
    "\n",
    "auto sum = 0;\n",
    "\n",
    "#pragma omp target teams distribute parallel for reduction( + : sum )\n",
    "                                                 ðŸ‘†\n",
    "for (auto i = 0; i < 100; ++i)\n",
    "    sum += i;\n",
    "\n",
    "std::cout << \"Sum is \" << sum << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8890b604",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise: 2D Stencil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1034a79a",
   "metadata": {},
   "source": [
    "This application solves a 2D finite difference discretization of the Laplace equation using Jacobi iterations.\n",
    "It can, among many other things, be used to simulate heat distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23157e6a",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/0/01/Heat.gif\" alt=\"heat equation\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7766ada5",
   "metadata": {},
   "source": [
    "For doing the exercise, understanding the finer details of the algorithm are not important.\n",
    "In essence, an update for each point of a 2D grid is computed based on the values of neighboring points in a repeating fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb39852",
   "metadata": {},
   "source": [
    "\n",
    "**If you have a background in *numerics*:**\n",
    "This is a *finite volume* or *finite difference* discretization of the heat equation $\\frac{\\partial u}{\\partial t} = \\alpha \\nabla^2 u$ using *central finite differences* for the spatial derivative (Laplacian) and an *explicit Euler* method for time stepping on a *Cartesian grid*.\n",
    "Each update computes a new value `uNew[i, j]` from the old field `u[i, j]` and its four nearest neighbors (two per cardinal direction).\n",
    "\n",
    "**If you have a background in *computer science*:**\n",
    "This is a *two-fold loop nest* applying a *local stencil operation*.\n",
    "Each grid point depends only on a *localized neighborhood*â€”in this case, the 4 cardinal neighbors.\n",
    "The pattern is usually memory-bound and well-suited for studying data movement, cache behavior, and domain decomposition across GPUs.\n",
    "\n",
    "**If you have a background in *image processing*:**\n",
    "This is a *filter* or *convolution*-like operation with a fixed kernel accessing neighboring pixels.\n",
    "The 'filter' runs repeatedly over time steps, effectively blurring (diffusing) a given image in each iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1615a",
   "metadata": {},
   "source": [
    "The serial baseline code is available at [code/exercise/stencil-2d.cpp](code/exercise/stencil-2d.cpp).\n",
    "It can be compiled and executed using the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2f06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -O3 -march=native -std=c++17 -Wall -o code/exercise/stencil-2d code/exercise/stencil-2d.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ccd80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!code/exercise/stencil-2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f1d29f",
   "metadata": {},
   "source": [
    "Optionally, the default parameters can be overwritten with `./stencil-2d num_cells_x_ num_cells_y num_iterations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe2d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!code/exercise/stencil-2d 1024 1024 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6cd877",
   "metadata": {},
   "source": [
    "Your task is to parallelize and port the application to GPU with OpenMP target offloading.\n",
    "In contrast to the previous exercises, this application does not perform a correctness check.\n",
    "Instead, it prints a single diagnostic number (the L2 norm of the residual).\n",
    "\n",
    "For **identical grid sizes and number of iterations**, this number must stay constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4a5206",
   "metadata": {},
   "source": [
    "Start by adding target data mappings and target offloading of the main loop\n",
    "\n",
    "```c++\n",
    "for (size_t j = 1; j < ny - 1; ++j) {\n",
    "    for (size_t i = 1; i < nx - 1; ++i) {\n",
    "        uNew[j * nx + i] = 0.25 * (  u[j * nx + i - 1] \\\n",
    "                                   + u[j * nx + i + 1] \\\n",
    "                                   + u[(j - 1) * nx + i] \\\n",
    "                                   + u[(j + 1) * nx + i]);\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165dbba5",
   "metadata": {},
   "source": [
    "You can compile and execute the application with the cells below afterwards (add `-gpu=mem:managed` if you want to use managed memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5516d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvc++ -O3 -std=c++17 -mp=gpu -Minfo=mp -o code/exercise/stencil-2d code/exercise/stencil-2d.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d04851",
   "metadata": {},
   "outputs": [],
   "source": [
    "!code/exercise/stencil-2d $((8 * 1024)) $((8 * 1024)) 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062f3b14",
   "metadata": {},
   "source": [
    "Compare performance for these scenarios:\n",
    "\n",
    "* parallelization of the **outer** loop only,\n",
    "* parallelization of the **inner** loop only, and\n",
    "* parallelization of **both** loops, e.g. using a `collapse` clause."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "146771a3-5182-4624-b1ac-8182bfa12776",
   "metadata": {},
   "source": [
    "Bonus: If you are done quickly, refactor the application once again to also perform the initialization and residual norm computation on GPU to avoid almost all data transfers between CPU and GPU:\n",
    "\n",
    "```c++\n",
    "for (size_t j = 0; j < ny; ++j) {\n",
    "    for (size_t i = 0; i < nx; ++i) {\n",
    "        if (0 == i || 0 == j || nx - 1 == i || ny - 1 == j) {\n",
    "            ...\n",
    "        } else {\n",
    "            ...\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "```c++\n",
    "double res = 0;\n",
    "for (size_t j = 1; j < ny - 1; ++j) {\n",
    "    for (size_t i = 1; i < nx - 1; ++i) {\n",
    "        const double localRes = 4 * u[j * nx + i] - (u[j * nx + i - 1] + u[j * nx + i + 1] + u[(j - 1) * nx + i] + u[(j + 1) * nx + i]);\n",
    "        res += localRes * localRes;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Can you get the application to run at **above 35,000 MLUPS** (around 560 GB/s bandwidth)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed5ed0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Possible Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59be210",
   "metadata": {},
   "source": [
    "A possible solution is given in [code/solution/stencil-2d.cpp](code/solution/stencil-2d.cpp).\n",
    "It can be compiled and executed using the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvc++ -O3 -std=c++17 -mp=gpu -o code/solution/stencil-2d code/solution/stencil-2d.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!code/solution/stencil-2d $((8 * 1024)) $((8 * 1024)) 64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
